{
    "config_name": "gpt-neo(sequential)",

    "layer_format": "transformer.h.{}",
    "layer_mlp_format": "transformer.h.{}.mlp",
    "layer_attn_format": "transformer.h.{}.attn",

    "ln1": "transformer.h.{}.ln_1",
    "attn_q": "transformer.h.{}.attn.attention.q_proj",
    "attn_k": "transformer.h.{}.attn.attention.k_proj",
    "attn_v": "transformer.h.{}.attn.attention.v_proj",
    "attn_o": "transformer.h.{}.attn.attention.out_proj",

    "ln2": "transformer.h.{}.ln_2",
    "mlp_ff1": "transformer.h.{}.mlp.c_fc",
    "mlp_ff2": "transformer.h.{}.mlp.c_proj",
    
    "parallel_attn_mlp_architecture": false,
    "include_mlp_bias": true,
    "include_attn_bias": true,

    "transpose_attn_o": true
}
